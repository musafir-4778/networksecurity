# Network Security Threat Detection Pipeline ğŸš¨

A modular machine learning pipeline to detect network security threats from structured network traffic data. Built using FastAPI, MongoDB, and scikit-learn models.

---

## ğŸ”‘ Key Features

- ğŸ”Œ **Data Ingestion:** Pulls network data from MongoDB collections.
- âœ… **Data Validation:** Verifies data schema and column counts.
- ğŸ”„ **Data Transformation:** Imputes missing values using KNN Imputer and prepares datasets.
- ğŸ¤– **Model Training:** Trains multiple classifiers (Random Forest, Logistic Regression, etc.) and selects the best-performing one.
- ğŸš€ **REST API:** FastAPI application to provide routes (root route confirmed).
- â˜ï¸ **MongoDB Atlas Integration:** Secure database connection using pymongo.

---

## ğŸ› ï¸ Folder Structure

```
networksecurity/
â”œâ”€â”€ app.py                # FastAPI app entry point (root route present)
â”œâ”€â”€ main.py               # Pipeline CLI script
â”œâ”€â”€ push_data.py          # MongoDB data insertion script
â”œâ”€â”€ testmongo.py          # MongoDB connection testing
â”œâ”€â”€ setup.py              # Package setup script
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ Dockerfile            # Docker configuration
â”œâ”€â”€ .env                  # Environment variables (MongoDB URL etc.)
â”œâ”€â”€ networksecurity/      # Core package modules
â”‚   â”œâ”€â”€ components/       # Data ingestion, validation, transformation, training
â”‚   â”œâ”€â”€ entity/           # Config & artifact dataclasses
â”‚   â”œâ”€â”€ constant/         # Pipeline constants
â”‚   â”œâ”€â”€ exception/        # Custom exception classes
â”‚   â”œâ”€â”€ logging/          # Logging utilities
â”œâ”€â”€ templates/            # Jinja2 templates (for possible future HTML routes)
â”œâ”€â”€ logs/                 # Logs generated by the pipeline
â”œâ”€â”€ final_model/          # Saved trained models
â”œâ”€â”€ Network_Data/         # Example datasets
â”œâ”€â”€ Artifacts/            # Saved artifacts during the pipeline
```

---

## âš™ï¸ How the Pipeline Works

### 1. Data Ingestion
- Pulls raw network data from a MongoDB Atlas database.
- Saves as raw CSV files for further processing.

### 2. Data Validation
- Verifies the number of columns & column names match the schema.
- (Future enhancement: add data drift detection.)

### 3. Data Transformation
- Uses a **KNNImputer** pipeline to handle missing data.
- Separates target column.
- Saves transformed features as NumPy arrays and the imputer pipeline as a `.pkl` file.

### 4. Model Training
- Trains multiple models (Random Forest, Logistic Regression, Decision Tree, etc.).
- Selects the best model using F1 score, precision, and recall.
- Saves the trained model and evaluation metrics.

### 5. Running the Pipeline
- Run the entire pipeline using a CLI script (`main.py`).
- The FastAPI app (`app.py`) currently serves the root route. Additional routes can be added.

---

## ğŸš€ Running the Application

### Setup
```bash
# Create virtual environment & activate
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Configure Environment
Create a `.env` file with:
```
MONGODB_URL=your-mongodb-atlas-url
```

### Run Training Pipeline via CLI
```bash
python main.py
```

### Run FastAPI Application (root route redirects to docs)
```bash
uvicorn app:app --reload
```
Visit: `http://localhost:8000/docs` to see the auto-generated API docs.

### Push Sample Data to MongoDB
```bash
python push_data.py
```

---

## ğŸ”§ Tech Stack

- Python 3.9+
- FastAPI
- MongoDB Atlas
- scikit-learn
- Pandas, NumPy

---

## âœ¨ Potential Future Enhancements

- Add experiment tracking with MLflow/Dagshub.
- Add `/train` or prediction API routes.
- Add automated model deployment endpoint.
- Add data drift detection during validation.
- Add authentication for API routes.

---

## ğŸ™Œ Author

- Lakshya Yadav

Feel free to fork and contribute to the project!
