# Network Security Threat Detection Pipeline 🚨

A modular machine learning pipeline to detect network security threats from structured network traffic data. Built using FastAPI, MongoDB, and scikit-learn models.

---

## 🔑 Key Features

- 🔌 **Data Ingestion:** Pulls network data from MongoDB collections.
- ✅ **Data Validation:** Verifies data schema and column counts.
- 🔄 **Data Transformation:** Imputes missing values using KNN Imputer and prepares datasets.
- 🤖 **Model Training:** Trains multiple classifiers (Random Forest, Logistic Regression, etc.) and selects the best-performing one.
- 🚀 **REST API:** FastAPI application to provide routes (root route confirmed).
- ☁️ **MongoDB Atlas Integration:** Secure database connection using pymongo.

---

## 🛠️ Folder Structure

```
networksecurity/
├── app.py                # FastAPI app entry point (root route present)
├── main.py               # Pipeline CLI script
├── push_data.py          # MongoDB data insertion script
├── testmongo.py          # MongoDB connection testing
├── setup.py              # Package setup script
├── requirements.txt      # Project dependencies
├── Dockerfile            # Docker configuration
├── .env                  # Environment variables (MongoDB URL etc.)
├── networksecurity/      # Core package modules
│   ├── components/       # Data ingestion, validation, transformation, training
│   ├── entity/           # Config & artifact dataclasses
│   ├── constant/         # Pipeline constants
│   ├── exception/        # Custom exception classes
│   ├── logging/          # Logging utilities
├── templates/            # Jinja2 templates (for possible future HTML routes)
├── logs/                 # Logs generated by the pipeline
├── final_model/          # Saved trained models
├── Network_Data/         # Example datasets
├── Artifacts/            # Saved artifacts during the pipeline
```

---

## ⚙️ How the Pipeline Works

### 1. Data Ingestion
- Pulls raw network data from a MongoDB Atlas database.
- Saves as raw CSV files for further processing.

### 2. Data Validation
- Verifies the number of columns & column names match the schema.
- (Future enhancement: add data drift detection.)

### 3. Data Transformation
- Uses a **KNNImputer** pipeline to handle missing data.
- Separates target column.
- Saves transformed features as NumPy arrays and the imputer pipeline as a `.pkl` file.

### 4. Model Training
- Trains multiple models (Random Forest, Logistic Regression, Decision Tree, etc.).
- Selects the best model using F1 score, precision, and recall.
- Saves the trained model and evaluation metrics.

### 5. Running the Pipeline
- Run the entire pipeline using a CLI script (`main.py`).
- The FastAPI app (`app.py`) currently serves the root route. Additional routes can be added.

---

## 🚀 Running the Application

### Setup
```bash
# Create virtual environment & activate
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Configure Environment
Create a `.env` file with:
```
MONGODB_URL=your-mongodb-atlas-url
```

### Run Training Pipeline via CLI
```bash
python main.py
```

### Run FastAPI Application (root route redirects to docs)
```bash
uvicorn app:app --reload
```
Visit: `http://localhost:8000/docs` to see the auto-generated API docs.

### Push Sample Data to MongoDB
```bash
python push_data.py
```

---

## 🔧 Tech Stack

- Python 3.9+
- FastAPI
- MongoDB Atlas
- scikit-learn
- Pandas, NumPy

---

## ✨ Potential Future Enhancements

- Add experiment tracking with MLflow/Dagshub.
- Add `/train` or prediction API routes.
- Add automated model deployment endpoint.
- Add data drift detection during validation.
- Add authentication for API routes.

---

## 🙌 Author

- Lakshya Yadav

Feel free to fork and contribute to the project!
